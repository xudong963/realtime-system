### 摘要



近年来，地方政府越来越重视以地铁为代表的城市轨道交通建设。地铁的普及大大改善城市地面交通拥堵和城市交通环境，使人们出行更加方便。分析和准确预测地铁客流一直是城市轨道交通管理部门的主要任务之一。特别是在轨道交通运力快速增长、乘客需求变化，人口稠密的城市越来越高度依赖交通系统的背景下，对客流分析的需求以及实现可靠，高效的资源利用和交通管理更为迫切。幸运的是，近几年，实时 ETL 技术不断成熟，可以充分的为地铁交通客流分析赋能。实时 ETL （即提取、转换和加载）的过程包括： 从外部来源提取数据； 将其改造以适应分析需要；将其加载到最终目标数据库或数据仓库。本文基于 ETL 和 Flink 等大数据技术，利用深圳地铁刷卡数据集，模拟实时刷卡场景，完成了对深圳地铁客流的分析。此设计的完成对解决城市拥堵问题，优化交通网络，保障公共交通，具有十分重要的意义。本文的主要研究为，调查地铁发展现状，分析地铁发展过程中遇到的问题；探索kafka，将redis后的数据，消费到kafka中，为下一阶段做准备；研究flink技术，模拟实时的流式传输，构造实时 ETL；学习clickhouse, 研究数据仓库的建模，作为数据的最终流向，可提供快速的分析结果；调研可视化方案，展示出实时清晰的动态结果。kafka, flink, clickhouse 都被阿里巴巴，腾讯，字节跳动等大型互联网公司采用，并且有着活跃开源社区的大数据技术，所以研究具有切实的可行性。



### 关键词

地铁；大数据技术；ETL；FLink；实时分析；数据仓库；kakfka；clickhouse



### 绪论

**研究背景**

城市轨道交通的飞速发展，已经大幅度减轻了城市地面交通的拥挤情况，不仅让人们的出行更加便利，而且带动了城市经济的发展。地铁虽然故障率低，运输量大，稳定安全，但是在一线城市，以深圳为例，大批的年轻人，打工族涌入，城市交通的负载进一步加重。到 2021 年为止，深圳总共有 11 条线地铁线路在运营，而 2021 年一月，10条(不包含深港地铁四号线)运营线路月客运量为16316万人次，各条线路的客运量如图1所示。

<img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20210413223746849.png" alt="image-20210413223746849" style="zoom: 25%;" />





**研究现状**

有研究基于地铁刷卡数据来对乘客的出行行为进行分析，采用的思路为，数据预处理；特征提取：根据行人的出行记录，进行行人进站时间聚类，得到乘客的固定出行天数，获取乘客的出行特征；乘客聚类：根据乘客的出行特征，进行乘客聚类。这个研究只是将乘客进行划分，可以对乘客进行定向推送特定的地铁信息，或者地铁站用来分析地铁高峰；但是这并不具有实时性，也没有将结果进行动态展示，而且分析的结果单一，只是对乘客进行了聚类，实际作用很局限。

另一项研究基于智能交通卡数据从多空间尺度研究地铁客流时间和空间分布特征，为城市公共交通需求管理提供科学依据，只是利用基本数据分析方法，将搜集的数据通过一些数学计算和图表分析，从全天、早高峰和晚高峰时段、市辖区尺度、环 路尺度、街道尺度，对北京市地铁客流的时空分布特征进行了系统性分析，并没有利用当前的先进的大数据技术，不具有实时性和动态性。

关于 ETL技术，传统上，ETL被安排为夜间批处理过程，以在非工作时间刷新数据。但是，随着科技的进步，24X7全天候业务运营模式，市场竞争以及引入现代数据源已迫使组织采取以下行动：更频繁地刷新其数据仓库，以提供近乎-实时环境。传统的ETL流程难以应对具有近实时环境的要求，因为它没有为此目的进行设计和优化。结果，更先进的ETL版本才能满足近乎实时环境，例如低延迟，高可用性和高扩展性。本文将模拟搭建一个实时 ETL 系统，用来进行研究。

**研究内容和意义**

客流的不断增加，但是地铁建设不能盲目增加，要和城市环境，地下空间相协调，于是促使着我们寻求新的方案来进一步提高地铁的便利，提高人们的乘车体验幸福感。互联网，大数据的爆发式发展，智慧城市，智慧生活的普及，促使着我们把目光转向物联网和大数据技术，物联网和大数据技术带来的工业 4.0 革命极大的影响了公共生活方式，刷卡进站逐渐演变为刷 APP 二维码即可，我们获取数据的方式越来越便捷，这是一个数据丰富和累积前所未有的时代。假如我们把这些数据利用起来，利用数据挖掘，实时计算，流式分析等大数据技术，实时提供高质量的交通运输信息，让人们实时的获取动态数据，方便规划行程或者采取其他交通方式，同时也方便交通部门分析人们的出行模式，提前规划未来城市交通的发展。调研后发现，随着大数据时代的发展，人们逐渐意识到传统 ETL 技术已经不能满足业务的需求，因为其加载周期是固定的，比较长的，一般是天级，周级，不能及时的对数据变化作出相应，与之相对应的是实时 ETL，其作为传统 ETL 的延伸，可以捕捉数据的快速变化并对数据做出实时的分析。实时数仓的发展经历了三个过程：lambda 架构，其在离线数仓的基础上增加了实时，通过流式计算引擎处理实时性业务；Kappa 架构直接全部采用实时部分，删去了多余的离线处理；几年来，OLAP 的发展越来越快，具有代表性的有阿里的 analyticDB 以及 俄罗斯的开源数据库Clickhouse，于是新的实时架构诞生了，这种架构的优点是将一部分计算从流式计算引擎，如 flink, spark 转移到了 OLAP 分析引擎上。本文将采用实时 OLAP 架构的 ETL 技术对深圳地铁的130多万条数据进行模拟，分析和展示数据结果，对行人出行，交通状况提出建议，帮助交通部门正确的规划下一步发展。

**其余部分安排**

本文的其他部分的结构如下。第二节相关工作介绍了本文使用的具体技术，如何利用大数据技术将数据集模拟为实时动态流，从而进行实时分析。第三节中，详细解释了本项目的需求是什么，将需求进行细粒度的拆分，大致描述每一个小需求所对应的具体解决方案。需求分为功能性需求和非功能性需求，功能性需求讲述了需要做出来什么，对应的流程是什么。而非功能性需求将从性能、安全、可维护性等方面进行阐述。在第四节中，将对项目的概要设计进行描述，包含数据库 ER 图，数据流框架图以及整个系统的设计。第五节将详细的介绍系统的每一部分设计以及功能是如何实现的，通过流程图，时序图以及类图等清晰的展现出来。在第六节中，我介绍了在系统设计和实现的过程中遇到的困难以及我是怎么解决的。最后一节，展示了系统的运行效果。并对系统进行展望，分析有哪些不足，未来该如果改进。



### 相关工作

获取133.7w条深圳地铁刷卡数据，将这些离线数据作为源头，经过 redis, kafka, flink, clickhouse 这条数据链路，构造实时 ETL 系统，最终将分析结果实时的动态展现出来。

搭建 ETL 系统，顾名思义，ETL具有三个主要方面阶段，每个阶段都照顾整体的特定部分数据刷新过程。提取阶段从异构数据系统读取数据并将其存储到中间存储中。转换阶段读取提取的数据，开展业务规则和基本数据操作，例如清理，数据类型转换等。加载阶段最终将转换后的数据加载到目标数据仓库。通常，数据仓库是通过按预定义的时间执行ETL流程，每天晚上刷新。这样可以确保用户可以在工作时间和ETL流程中使用最新的数据，无需与用户查询竞争资源。少数其他因素，例如业务需求最近的数据，数据仓库的处理能力和源数据的性质也可能会产生影响关于数据刷新的频率。本系统属于实时范畴。

采用 redis 来存储源数据，redis 是一个高性能的 kv 数据库，很多公司将其作为缓存层，在本项目中，将其作为持久化存储数据库。因为 redis 具有天然去重, 自动排序的特性，使用 HSET 命令可以将 json 文件中的数据无重复的写入到 redis 中。其写入性能相当好，可以到达 8.1w次/s，节省了很多时间。

kafka 作为具有高吞吐，可持久化，支持数据流处理的分布式流式计算平台，在本项目中起着承前启后的作用，连接生产者和消费者，即 redis 和 clickhouse。Kafka 有三大角色消息系统、存储系统、流式处理平台。本项目采用了消息系统和流式处理平台两个角色，消息系统和流式处理平台，作为消息系统，其体系结构中引入了生产者和消费者，生产者是发送消息的一方，负责创建消息，通过 flink 的连接，redis 中的数据被送到 kafka 中，消费者是接收消息的一方，通过 flink 的连接，clickhouse 获取到了来自 kafka 的数据。Kafka 具有高吞吐，低延时和高可用的消息传输能力，这使得其成为流式系统中十分优秀的数据来源，如 Apache Flink 就将其作为可靠数据源，本项目也是这样来构造数据流式链路的。kafka 的生态十分丰富，在进行 ETL 的过程中，我使用了 Kafka-eagle 来监控数据流量。

再谈谈 Flink 在该项目中发挥的作用，Flink 式处理流批数据的开源系统，在实时 ETL 中的充当着重要的角色，从头到尾都可以看到 Flink 的影子。Apache Flink遵循一个范例，该范例将流及批处理在编程模型和执行引擎中统一。流处理结合了持久消息队列（如 kafka），在实时处理最新事件、在大窗口中周期持续的聚合数据或处理数 TB 的历史数据之间不作区分。这些不同类型的计算只是在持久流的不同点开始处理，并在计算过程中保持不同形式的状态。通过高度灵活的窗口机制，Flink 可以用相同的操作执行 lambda 架构的多路计算。Flink 支持不同的时间概念（事件时间、进入时间、处理时间），以便让程序员在定义事件应如何关联方面具有高度的灵活性。本项目中大量使用了 Flink 提供的 API，完成 ETL 的三个阶段，并且模拟出了实时的效果。

Clickhouse 是当下最火的 OLAP 数据仓库之一，由俄罗斯的 Yandex 开发并开源，该数据库的特点包括，在读多写少的场景下性能极佳，我的项目正好是这一场景，需要频繁的读取数据进行分析，又应为实时的原因，要求读数据的速度很快；在大宽表，读大量的行但是只用到很少列的时，不需要全部读取；采用列式存储，列存在分析性场景中有很多的优势，如果不需要参与计算的列被读取出来，势必会导致读放大，采用列存后，只需读取参与计算的列到内存即可，大大降低了磁盘 I/O，查询速度大大加快，更有利于实时场景。在分析前时，需要多某些列进行计算，clickhouse 在计算层做了很多的优化，划分 partition, 充分发挥 CPU 的多核心实现数据的并行处理，这样一来，一条 query 就可以将大部分的 CPU 都利用起来，从根本上降低查询的延迟。Clickhouse 内部实现了向量执行引擎，并且将数据在内存中也按列存储，这样可以提高缓存命中率，内部计算按批执行，一批计算调用一次 SIMD 指令，充分发挥 SIMD 的并行能力。

前端展示采用了 EasyV 提供的可视化大屏展示服务，可以快速上手，通过对 clickhouse 进行查询，将得到的结果按照显示在面板的对应的部分，实时的对结果进行更正，清晰的将分析结果展示给乘客。



### 系统架构设计与分析

项目的架构设计如下

<img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20210421155634191.png" alt="image-20210421155634191" style="zoom:67%;" />





整条数据流链路分为四段，每一段都需要将数据完整的，实时的，可靠的，高效的输送的下一个阶段。鉴于此目的，全程采用 Flink  编程模型和 APIs，因为 Flink 的架构十分清晰，APIs 方便快捷。Flink 的架构氛围为软件栈和分布式系统。虽然 Flink 的 API 栈仍在增长，但可以区分四个主要层：部署、核心、APIs 和库。

<img src="/var/folders/8n/b2zm4d_x2qz149vtcfd7j_yr0000gp/T/com.yinxiang.Mac/WebKitDnD.rRyXoK/7D41AB0F-05A2-46F7-9951-69A53C0DA0E4.png" alt="7D41AB0F-05A2-46F7-9951-69A53C0DA0E4" style="zoom:67%;" />

将深圳地铁刷卡数据流式写入 redis 中，供 kafka 消费，Flink 的 Java DataStream API 可以将任意可序列化对象转换为流，将 json 数据集作为数据源，通过 flink streaming 流式的将数据传输到 redis，同时启动 Kafka，redis 作为生产者，源源不断的将过滤后的数据输送到 kafka 的 topic 中，线程采取随机睡眠的方式尽可能模拟出真实的流式场景。最后采用 OLAP 数据库 clickhouse 作为消费者，通过 flink 消费 kafka topic 中的数据，作为 ODS 存储起来。文件到 redis, redis 到 kafka, kafka 到 clickhouse 都是 flink 流式应用，下面讲解一个 flink 流式应用的执行过程，在这个过程中我们需要做什么，从而保证整条流的稳定高效。

因为项目的需求是实时和流式，所以主要采用了 DataStream API 进行流处理。执行 Flink 流式应用第一步要做的事情就是设置执行环境，执行环境可以是集群或者本地机器，本项目直接在本地机器上执行；配置完执行环境后，需要创建流式数据源，这些数据源可以来自文件或者消息队列，也可以是实时产生的，比如传感器数据，web 页面点击产生的数据，创建数据源的最终目的是将其传到下一个应用中。拿到数据源后，需要对其进行转化，生成新的数据源。然后新生成的数据源会被发送到外部系统，在本项目中，外部系统包括，redis, kafka, clickhouse。flink 采用的是延迟执行的方式，上面环境配置，生成数据源和数据转化是不会触发 flink 的计算的，只有调用 execute() API 后，才会真正的执行。执行任务交给了 JobManager, 最终到达外部系统。

我们最终的目的是根据 ODS 中的实时数据，分析出地铁的流量，高峰期，不同车站的人流等等，并实时的进行展示。所以需要严格的按照数据仓库的建模步骤进行建模。首先需要对 ODS 进行分层，分为 DWD(数据细节层) 和 DWS(数据汇总层)。DWD, 是业务层与数据仓库的隔离层。主要对ODS数据层做一些数据清洗和规范化的操作。DWS, 数据汇总层，基于DWD上的基础数据，整合汇总成分析某一个主题域的服务数据层，一般是宽表。用于提供后续的业务查询，OLAP分析等。然后根据展示需要，从不同的维度构建维度表, 从而形成星型表结构，对每一个维度表进行查询和分析，得到最终的展示信息。

如何进行最终的结果展示，调研了 Datav, FindReport, echart, EasyV 等多种可视化工具后，发现EasyV 很好的支持了 clickhouse，并且使用起来相对容易上手，所以最终决定使用 EasyV 将从维度表中分析出来的数据结果展示在前端上。

非功能性需求包括，数据一致性，系统整体容错性，稳定性，流量控制。这些在 flink 中都能得到保障。

Flink 通过严格的一次处理一致性保证提供可靠的执行，并通过检查点和部分重执行处理故障。系统为有效提供这些保证而作出的一般假设是，数据源是持久和可重播的。此类数据源的例子包括文件和持久消息队列（例如 Kafka）。在实践中，也可以通过在源数据算子的状态内保留WAL来合并非持久数据源。Apache Flink 的检查点机制以分布式一致性快照的概念为基础来实现一次处理保证。数据流可能无界的性质使得在恢复时重新计算不切实际，因为可能需要重播数月的计算，这是长期的工作。为了限制恢复时间，Flink 会定期保存算子状态的快照，包括输入流的当前位置。

Flink 通过设置并行度的方法来控制流量的大小。把一个 DataStream 提交到 JobManager 后，生成的 DAG 就准备执行算子，每个算子可以产生一到多个任务，并行度就是执行任务的数目。



### 实时数据库设计与分析

// 数据库设计

ODS table （原始数据库表）

| 列名         | 数据类型 | 是否为空 | 备注                      |
| ------------ | -------- | -------- | ------------------------- |
| deal_date    | String   | null     | 进站(交易)时间            |
| close_date   | String   | null     | 出战(结算)时间            |
| card_no      | String   | null     | 卡号                      |
| deal_value   | String   | null     | 实收费用                  |
| deal_type    | String   | null     | 交通类型 (进站/出站/巴士) |
| company_name | String   | null     | 地铁线名                  |
| car_no       | String   | null     | 车号                      |
| station      | String   | null     | 站名                      |
| conn_mark    | String   | null     | 联程标记                  |
| deal_money   | String   | Null     | 应收费用                  |
| equ_no       | String   | Null     | 闸机号                    |

DWD 清洗和降维

清洗掉 bus 相关的数据 且不在地铁运营时间的数据

| 列名         | 数据类型 | 是否为空 | 备注                 |
| ------------ | -------- | -------- | -------------------- |
| deal_date    | String   | null     | 进站(交易)时间       |
| close_date   | String   | null     | 出战(结算)时间       |
| card_no      | String   | null     | 卡号                 |
| deal_value   | String   | null     | 实收费用             |
| deal_type    | String   | null     | 交易类型 (进站/出站) |
| company_name | String   | null     | 地铁线名             |
| car_no       | String   | null     | 车号                 |
| station      | String   | null     | 站名                 |
| conn_mark    | String   | null     | 联程标记             |
| deal_money   | String   | Null     | 应收费用             |
| equ_no       | String   | Null     | 闸机号               |

进一步降维，分为进站和出战 

> 进站

| 列名         | 数据类型 | 是否为空 | 备注            |
| ------------ | -------- | -------- | --------------- |
| deal_date    | String   | null     | 进站(交易)时间  |
| card_no      | String   | null     | 卡号            |
| deal_type    | String   | null     | 交易类型 (进站) |
| company_name | String   | null     | 地铁线名        |
| car_no       | String   | null     | 车号            |
| station      | String   | null     | 站名            |
| equ_no       | String   | Null     | 闸机号          |

> 出战

| 列名         | 数据类型 | 是否为空 | 备注            |
| ------------ | -------- | -------- | --------------- |
| deal_date    | String   | null     | 进站(交易)时间  |
| close_date   | String   | null     | 出战(结算)时间  |
| card_no      | String   | null     | 卡号            |
| deal_value   | String   | null     | 实收费用        |
| deal_type    | String   | null     | 交易类型 (出站) |
| company_name | String   | null     | 地铁线名        |
| car_no       | String   | null     | 车号            |
| station      | String   | null     | 站名            |
| conn_mark    | String   | null     | 联程标记        |
| deal_money   | String   | Null     | 应收费用        |
| equ_no       | String   | Null     | 闸机号          |

DWS

1.站点进站人数排行榜

| 列名          | 数据类型      | 是否为空 | 备注               |
| ------------- | ------------- | -------- | ------------------ |
| station       | String        | Null     | 站名               |
| deal_dates    | ARRAY<STRING> | Null     | 进站(交易)时间集合 |
| card_nos      | ARRAY<STRING> | Null     | 卡号集合           |
| company_names | ARRAY<STRING> | Null     | 地铁战线集合       |
| equ_nos       | ARRAY<STRING> | Null     | 闸机号集合         |
| Rank          | Int           | Null     | 排名               |

2.站点出站人数排行榜

| 列名          | 数据类型      | 是否为空 | 备注               |
| ------------- | ------------- | -------- | ------------------ |
| station       | String        | Null     | 站名               |
| deal_dates    | ARRAY<STRING> | Null     | 进站(交易)时间集合 |
| card_nos      | ARRAY<STRING> | Null     | 卡号集合           |
| deal_values   | ARRAY<STRING> | Null     | 实收费用集合       |
| company_names | ARRAY<STRING> | Null     | 地铁战线集合       |
| conn_marks    | ARRAY<STRING> | Null     | 联乘标记集合       |
| deal_moneys   | ARRAY<STRING> | Null     | 应收费用集合       |
| equ_nos       | ARRAY<STRING> | Null     | 闸机号集合         |
| Rank          | Int           | Null     | 排名               |

3.站点进出站人数排行榜

| 列名          | 数据类型      | 是否为空 | 备注               |
| ------------- | ------------- | -------- | ------------------ |
| station       | String        | Null     | 站名               |
| deal_dates    | ARRAY<STRING> | Null     | 进站(交易)时间集合 |
| card_nos      | ARRAY<STRING> | Null     | 卡号集合           |
| deal_values   | ARRAY<STRING> | Null     | 实收费用集合       |
| deal_types    | ARRAY<STRING> | Null     | 交易类型集合       |
| company_names | ARRAY<STRING> | Null     | 地铁战线集合       |
| conn_marks    | ARRAY<STRING> | Null     | 联乘标记集合       |
| deal_moneys   | ARRAY<STRING> | Null     | 应收费用集合       |
| equ_nos       | ARRAY<STRING> | Null     | 闸机号集合         |
| Rank          | Int           | Null     | 排名               |

4.站点盈利排行榜

| 列名           | 数据类型 | 是否为空 | 备注         |
| -------------- | -------- | -------- | ------------ |
| station        | String   | Null     | 站名         |
| company_name   | String   | Null     | 地铁战线     |
| deal_money_sum | Float64  | Null     | 应收费用集合 |
| deal_value_sum | Float64  | Null     | 实收费用集合 |

数据流图



### 功能详细设计

redis 是目前最火的存储中间件，它以超高的性能，清晰的文档，简洁的源码被程序员一致好评。国内外大型互联网公司都在用。本项目中主要采用了 redis 的存储功能，通过 flink api 将离线数据集写入到 redis 中。redis 中的数据结构有很多，项目中使用了哈希对象，创建 FlinkJedis 配置后，通过提供的 RedisSink将数据以 page 为 key 插入到 redis 中。redis 当前HashMap的实现有两种方式：当HashMap的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，这时对应的 value 的 redisObject 的编码为zipmap，当键值对数量增加时会自动转成真正的 HashMap, 编码便车给你为ht，hashmap 的 key 是不可重复的，可以对数据进行一次去重操作。RedisSink 是使用Jedis客户端将数据传递到Redis通道的 sink，这个 sink 可以使用三种不同的方法与不同类型的Redis环境进行通信：1.单个Redis服务器2. Redis集群3. Redis哨兵。我们使用了单个服务器完成通信。

```java
public class JsonToRedis {

  public static void main(String[] args) throws Exception {

    StreamExecutionEnvironment streamExecutionEnvironment = StreamExecutionEnvironment
        .getExecutionEnvironment();
    // get flink data stream
    DataStreamSource<String> datastream = streamExecutionEnvironment
        .readTextFile("dataset/dataset.json").setParallelism(1);
    ...
    //for sending data to Redis.
    parsed.addSink(new RedisSink<JSONObject>(conf, new RedisSinkFunc()));
    streamExecutionEnvironment.execute("JSON to Redis");
  }
}

class RedisSinkFunc implements RedisMapper<JSONObject> {

  @Override
  public RedisCommandDescription getCommandDescription() {
    return new RedisCommandDescription(RedisCommand.HSET, "pageJSON");
  }

  @Override
  public String getKeyFromData(JSONObject jsonObject) {
    return jsonObject.getInteger("page").toString();
  }
  ...
}
```

由于其采用了多路复用 io 阻塞机制，数据结构简单，操作便捷使得数据在写入 redis 过程中十分的高效。因为 redis 的瓶颈不在 cpu, 主要在网络带宽和内存的大小，所以redis 是单线程，单线程切换的开销很小，可以避免不必要的竞争，不需要加锁，进一步提高了 redis 的性能。通过 RDB 持久化，在某个时间将数据都写到磁盘上，可以防止数据丢失，安全可靠。



kafka 已经成为互联网公司数据管道的关键组成部分。项目中引入了Kafka，这是一个分布式消息传递系统，它来收集和传递大量低延迟的数据，适合在线消息的使用。kafka 的架构包含N个 Producer， N个 Consumer, N 个 Broker, 还有一个 zookeeper 集群，Broker 负责将收到的消息存到磁盘上。Producer 负责发功消息到 Broker, Consumer 负责从 Broker 中取消息。另外，Kafka 中还有 topic 和 partition 的概念，生产者会把消息发送到指定的 topic, 然后消费者通过订阅 topic 拿到消息。生产逻辑由以下步骤组成

- 参数配置：包含客户端参数和生产者实例

  ```java
  Properties properties = new Properties();
      properties.setProperty("bootstrap.servers", "");
  FlinkKafkaProducer<String> producer = new FlinkKafkaProducer<String>(
        "my-topic",
        new ProducerStringSerializationSchema("my-topic"),
        properties,
        Semantic.EXACTLY_ONCE);
  ```

- 创建需要发送的消息，即 redis 中的数据源，这里要再进行一下过滤

  ```java
  class FilterRedisSource extends RichSourceFunction<String> {
    @Override
    public void run(SourceContext<String> sourceContext) throws Exception {
      jedis_ = getJedisClient();
      for(int i = 1; i <= PAGECNT; ++i) {
        String value = jedis_.hget("pageJSON", i + "");
        // System.out.println(value);
        JSONObject jsonVal = JSON.parseObject(value);
        // {"data": [{}, {}, {}]}
        JSONArray dataArray = jsonVal.getJSONArray("data");
        for (Object element: dataArray) {
          String val = element.toString();
          JSONObject jVal = JSON.parseObject(val);
          if(jVal.size() == ELESIZE) {
            sourceContext.collect(val);
          }
        }
      }
    }
    ...
  }
  ```

- 消息构建完成后，就需要借助 Flink DataStream API 进行发送，首先需要先创建StreamExecutionEnvironment，然后把DataSource 加入到执行环境中，执行即可，这样消息就会被流式的发送。

  ```java
  public class RedisToKafka {
  
    public static void main(String[] args) throws Exception {
      StreamExecutionEnvironment streamExecutionEnvironment = StreamExecutionEnvironment
          .getExecutionEnvironment().setParallelism(1);
      Properties properties = new Properties();
      properties.setProperty("bootstrap.servers", "");
      SingleOutputStreamOperator<String> dataStreamSource = streamExecutionEnvironment.addSource(new FilterRedisSource()).map(
          (MapFunction<String, String>) s -> {
            //Simulate real-time state
            Thread.sleep(ThreadLocalRandom.current().nextInt(0, 10));
            return s;
          });
      FlinkKafkaProducer<String> producer = new FlinkKafkaProducer<String>(
        "my-topic",
        new ProducerStringSerializationSchema("my-topic"),
        properties,
        Semantic.EXACTLY_ONCE);
      dataStreamSource.addSink(producer);
      streamExecutionEnvironment.execute("Redis To Kafka");
    }
  }
  ```

- 最后，如果已经没有消息需要发送了，就可以关闭生产者

  ```java
   public void cancel() {
      jedis_.close();
   }
  ```

数据源源不断的从 redis 流入到 kafka 的 topic 中，此时需要消费者及时的从 kafka 的 topic 中取出数据，流入到 clickhouse 中。消费者的消费逻辑由以下步骤组成

- 参数配置：包含消费者客户端参数和消费者实例，需要注意的是，kafka 的消费组成中有一层消费组，每个消费者跟一个消费组对应。实际上topic 是被消费组订阅的，消息一旦发布，会被投送到订阅这个消息的消费组里的消费者中。所以需要指定一下消费组的 id。消费者和消费组这种模式有一个好处就是可以提高消费能力的横向拓展性，通过增加消费者或者减少消费者来提高或者削弱消费能力。

  ```java
  Properties properties = new Properties();
  properties.setProperty("bootstrap.servers", "10.227.89.202:9092");
  properties.setProperty("group.id", "test-consumer-group");
  ```

- 消费组订阅指定的 topic, 将 kafka topic 中的数据作为 DataStreamSource。

  ```java
  SingleOutputStreamOperator<String> dataStreamSource = streamExecutionEnvironment
    .addSource(new FlinkKafkaConsumer<>(
      "my-topic",
      new SimpleStringSchema(),
      properties).setStartFromEarliest()
              ).map((MapFunction<String, String>) s -> {
    Thread.sleep(ThreadLocalRandom.current().nextInt(0, 10));
    return s;
  });
  ```

- 指定消息的去处，即Data Sink。这里是将数据消费到 clickhouse 中，为了保证数据的稳定传输，这里使用 jdbc 进行连接

  ```java
  dataStreamSource.addSink(new FlinkToCK("10.227.89.202", 8123 + "", "default", "123"));
  
  public void open(Configuration param) throws SQLException {
    this.connection_ = DriverManager.getConnection("jdbc:clickhouse://" + host_ + ":" + port_, user_, pwd_);
    connection_.createStatement().execute("CREATE TABLE IF NOT EXISTS test (" +
                                          "first Nullable(String)) ENGINE = Memory()"
                                         );
  }
  ```

- 一切就绪后，就可以在流式执行环境中拉取消息进行消费

  ```java
  streamExecutionEnvironment.execute("flink consume kafka topic");
  ```

- 消费完成后，关闭连接器

  ```java
  public void close() throws SQLException {
    connection_.close();
  }
  ```

至此，数据被存到了OLAP 分析型数据库 clickhouse 中，数据仓库建模完成后，可以把原始数据进行多维度的细化，用于最后的分析场景中。

上述功能的实现，都离不开 flink, flink 贯穿整条功能链。Flink 作为一个开源的流式框架，它的高性能，高可用，以及易用性保证了实时场景的稳定模拟，Flink 的特点是计算是有状态的，可以实时的记录计算状态，Exactly-once 可以保证失败恢复可以正确的进行。状态在计算中无处不在，由于实时场景中的数据一般是无限的，所以为了避免内部状态的无限增长，算子一般保留的是一个摘要状态，可以节省计算资源。Flink 中蕴含着 DataFlow 的编程思想，其描述了不同操作之间的数据如何流动，DataFlow 的表现形式是一个 DAG，即有向无环图。执行 Flink 程序的过程，就是在执行一个个 DAG, 这个过程是可以并行进行的，可以更好的利用计算资源。

本项目无时不刻的在使用 Flink DataStream 的 API，包括 DataSource, Transformation, Sink 等等。DataSource 的含义是数据源，通过下面的方式就可以添加数据源，这时候可以指定一下并行度，默认情况下，算子的并行度与算子执行的应用环境并行度相关联。

```java
StreamExecutionEnvironment
        .getExecutionEnvironment().addSource();
```

Transformation 是对数据的具体操作，比如 Map, Filter等。项目中主要用到的是 map， 直接通过一个 lambda 算子就可以对数据进行过滤或者类型转换，lambda 算子提供了简明的方式实现具体的操作逻辑。

```java
(MapFunction<String, String>) s -> {
          Thread.sleep(ThreadLocalRandom.current().nextInt(0, 10));
          return s;
        }
```

Sink，故名思义，「沉入」，即数据将被存储到新的存储介质中，在本项目中包括，redis, kafka, clickhouse。

世间没有银弹，Hadoop 的生态有时候确实比较笨重，在实时性和海量数据场景下，Hadoop 不太能够应付。Clickhouse 的诞生为大大的为 BI 赋能，虽然分析型数据库层出不穷，包括以Mysql 为代表的关系型数据库，HIVE，SparkSql，但是它们都被具有丰富功能的 clickhouse 打败。其支持在线实时查询，采用列式存储，有完善的 SQL 支持，并且不依赖 Hadoop 生态，还有其最大的特色，查询性能非常高，在很多基准测试的比较重，Clickhouse 都名列前矛，所以我最终决定采用 Clickhouse 作为本项目的实时数仓。

clickhouse 完全支持标准的 JDBC 协议，Http 通信接口作为底层。

```java
class FlinkToCK extends RichSinkFunction<String> {

  FlinkToCK(String host, String port, String user, String pwd) {
    super();
    host_ = host;
    port_ = port;
    user_ = user;
    pwd_ = pwd;
  }

  @Override
  public void invoke(String value, SinkFunction.Context context) throws SQLException {
    String sql = "INSERT INTO test (first) VALUES (?)";
    PreparedStatement statement = connection_.prepareStatement(sql);
    statement.setString(1, value);
    statement.addBatch();
    statement.executeBatch();
  }

  public void close() throws SQLException {
    connection_.close();
  }

  @Override
  public void open(Configuration param) throws SQLException {
    this.connection_ = DriverManager.getConnection("jdbc:clickhouse://" + host_ + ":" + port_, user_, pwd_);
    connection_.createStatement().execute("CREATE TABLE IF NOT EXISTS test (" +
        "first Nullable(String)) ENGINE = Memory()"
    );
  }
  ...
}
```

原始数据进入 clickhouse 后，就是数据仓库建模的第一步，得到 ODS，即原始数据表。

```sql
    // ods table
    this.connection_.createStatement().execute("DROP TABLE IF EXISTS ods_subway_data");
    connection_.createStatement().execute("CREATE TABLE IF NOT EXISTS ods_subway_data (" +
                                          "deal_date Nullable(String),"
                                          + "close_date Nullable(String),"
                                          + "card_no Nullable(String),"
                                          + "deal_value Nullable(String),"
                                          + "deal_type Nullable(String),"
                                          + "company_name Nullable(String),"
                                          + "car_no Nullable(String),"
                                          + "station Nullable(String),"
                                          + "conn_mark Nullable(String),"
                                          + "deal_money Nullable(String),"
                                          + "equ_no Nullable(String)"
                                          + ") ENGINE = Memory()"
                                         );
    String sql = "INSERT INTO ods_subway_data (deal_date, close_date, card_no, deal_value, deal_type, company_name, car_no, station, conn_mark, deal_money, equ_no) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
    PreparedStatement statement = connection_.prepareStatement(sql);
    Map<String, String> mapVal = new Gson().fromJson(
      value, new TypeToken<HashMap<String, String>>() {}.getType()
    );
    statement.setString(1, mapVal.get("deal_date"));
    statement.setString(2, mapVal.get("close_date"));
    statement.setString(3, mapVal.get("card_no"));
    statement.setString(4, mapVal.get("deal_value"));
    statement.setString(5, mapVal.get("deal_type"));
    statement.setString(6, mapVal.get("company_name"));
    statement.setString(7, mapVal.get("car_no"));
    statement.setString(8, mapVal.get("station"));
    statement.setString(9, mapVal.get("conn_mark"));
    statement.setString(10, mapVal.get("deal_money"));
    statement.setString(11, mapVal.get("equ_no"));
    statement.addBatch();
    statement.executeBatch();
  }
```



维度建模是数据仓库领域的数据仓库建模的代表。数据仓库的核心目标就是为展示层提供清晰的结果。维度建模就是为 OLAP 的场景创造的，灵活分解分析的需求，在海量数据场景下能够快速响应。

数据仓库建模的第二步，对 DW 进行分层，DW 是数据仓库的核心，一般是三层结构。这种分层是为了更好的组织，管理和维护数据。所以数据仓库分层是数据仓库设计中的重要一环。分层后的业务表可以直接呈现给上层，还可以减少重复的计算和存储资源的浪费。DW 分为 DWD, DWB, DWS 三层，这里主要使用了 DWD (数据细节层) 和 DWS (数据汇总层) 

在 DWD 层，做了一些清理数据的工作，清洗掉 bus 相关的数据 且不在地铁运营时间的数据。提高了数据的质量，会后续提供了了干净，一致的可靠数据

```sql
    this.connection_.createStatement().execute("DROP TABLE IF EXISTS dwd_subway_data");
    connection_.createStatement().execute("CREATE TABLE IF NOT EXISTS dwd_subway_data (" +
                                          "deal_date Nullable(String),"
                                          + "close_date Nullable(String),"
                                          + "card_no Nullable(String),"
                                          + "deal_value Nullable(String),"
                                          + "deal_type Nullable(String),"
                                          + "company_name Nullable(String),"
                                          + "car_no Nullable(String),"
                                          + "station Nullable(String),"
                                          + "conn_mark Nullable(String),"
                                          + "deal_money Nullable(String),"
                                          + "equ_no Nullable(String)"
                                          + ") ENGINE = Memory()"
                                         );
     String dwd_subway_data_sql = "INSERT INTO dwd_subway_data (deal_date, close_date, card_no, deal_value, deal_type, company_name, car_no, station, conn_mark, deal_money, equ_no) SELECT "
        + "deal_date,"
        + "close_date,"
        + "card_no,"
        + "deal_value,"
        + "deal_type,"
        + "company_name,"
        + "car_no,"
        + "station,"
        + "conn_mark,"
        + "deal_money,"
        + "equ_no "
        + "FROM ods_subway_data "
        + "WHERE deal_type != '巴士'";
    statement = connection_.prepareStatement(dwd_subway_data_sql);
```

然后进一步进行降维操作，分为进站和出战两个层次，方便 DWS 层做汇聚

```sql
    // 进站
    this.connection_.createStatement().execute("DROP TABLE IF EXISTS dwd_in_station_data");
    connection_.createStatement().execute("CREATE TABLE IF NOT EXISTS dwd_in_station_data (" +
                                          "deal_date Nullable(String),"
                                          + "card_no Nullable(String),"
                                          + "deal_type Nullable(String),"
                                          + "company_name Nullable(String),"
                                          + "car_no Nullable(String),"
                                          + "station Nullable(String),"
                                          + "equ_no Nullable(String)"
                                          + ") ENGINE = Memory()"
                                         );
    String dwd_in_station_data =
      "INSERT INTO dwd_in_station_data (deal_date, card_no, deal_type, company_name, car_no, station, equ_no) SELECT "
          + "deal_date,"
          + "card_no,"
          + "deal_type,"
          + "company_name,"
          + "car_no,"
          + "station,"
          + "equ_no "
          + "FROM dwd_subway_data "
          + "WHERE deal_type == '地铁入站'";
    statement = connection_.prepareStatement(dwd_in_station_data);
```

```sql
    // 出战
    this.connection_.createStatement().execute("DROP TABLE IF EXISTS dwd_out_station_data");
    connection_.createStatement().execute("CREATE TABLE IF NOT EXISTS dwd_out_station_data (" +
        "deal_date Nullable(String),"
        + "close_date Nullable(String),"
        + "card_no Nullable(String),"
        + "deal_value Nullable(String),"
        + "deal_type Nullable(String),"
        + "company_name Nullable(String),"
        + "car_no Nullable(String),"
        + "station Nullable(String),"
        + "conn_mark Nullable(String),"
        + "deal_money Nullable(String),"
        + "equ_no Nullable(String)"
        + ") ENGINE = Memory()"
    );
    String dwd_out_station_data_sql =
        "INSERT INTO dwd_out_station_data (deal_date, close_date, card_no, deal_value, deal_type, company_name, car_no, station, conn_mark, deal_money, equ_no) SELECT "
            + "deal_date,"
            + "close_date,"
            + "card_no,"
            + "deal_value,"
            + "deal_type,"
            + "company_name,"
            + "car_no,"
            + "station,"
            + "conn_mark,"
            + "deal_money,"
            + "equ_no "
            + "FROM dwd_subway_data "
            + "WHERE deal_type == '地铁出站'";
    statement = connection_.prepareStatement(dwd_out_station_data_sql);
    statement.execute();
```

在 DWS 层，基于 DWD 层的基本数据，将某个主题的服务数据进行集成和汇总，DWS 层将覆盖应用场景，可以快速响应数据需求。包含以下的主题

站点进站人数排行榜

```sql
    connection_.createStatement().execute("DROP TABLE IF EXISTS  dwd_in_station_rank");
    connection_.createStatement().execute("CREATE TABLE  IF NOT EXISTS dwd_in_station_rank (" +
                                          "station Nullable(String),"
                                          + "deal_dates Array(String),"
                                          + "card_nos Array(String),"
                                          + "company_names Array(String),"
                                          + "equ_nos Array(String),"
                                          + "nums Int64"
                                          + ") ENGINE  = MergeTree() order by nums"
                                         );
    String dwd_in_station_rank_sql =
        "INSERT INTO dwd_in_station_rank (station, deal_dates, card_nos, company_names, equ_nos, nums) SELECT "
            + "station,"
            + "groupArray(deal_date),"
            + "groupArray(card_no),"
            + "groupArray(company_name),"
            + "groupArray(equ_no),"
            + "count(*) nums "
            + "FROM dwd_in_station_data "
            + "GROUP BY station "
            + "ORDER BY nums DESC";
    statement = connection_.prepareStatement(dwd_in_station_rank_sql);
    statement.execute();
```

站点出站人数排行榜

```sql
    connection_.createStatement().execute("DROP TABLE IF EXISTS  dwd_out_station_rank");
    connection_.createStatement().execute("CREATE TABLE  IF NOT EXISTS dwd_out_station_rank (" +
                                          "station Nullable(String),"
                                          + "deal_dates Array(String),"
                                          + "card_nos Array(String),"
                                          + "deal_values Array(String),"
                                          + "company_names Array(String),"
                                          + "conn_marks Array(String),"
                                          + "deal_moneys Array(String),"
                                          + "equ_nos Array(String),"
                                          + "nums Int64"
                                          + ") ENGINE  = MergeTree() ORDER BY nums"
                                         );
    String dwd_out_station_rank_sql =
        "INSERT INTO dwd_out_station_rank (station, deal_dates, card_nos, deal_values, company_names, conn_marks, deal_moneys, equ_nos, nums) SELECT "
            + "station,"
            + "groupArray(deal_date),"
            + "groupArray(card_no),"
            + "groupArray(deal_value),"
            + "groupArray(company_name),"
            + "groupArray(conn_mark),"
            + "groupArray(deal_money),"
            + "groupArray(equ_no),"
            + "count(*) nums "
            + "FROM dwd_out_station_data "
            + "GROUP BY station "
            + "ORDER BY nums DESC";
    statement = connection_.prepareStatement(dwd_out_station_rank_sql);
    statement.execute();
```

站点进站出站人数排行榜

```sql
    connection_.createStatement().execute("DROP TABLE IF EXISTS  dwd_in_out_station_rank");
    connection_.createStatement().execute("CREATE TABLE  IF NOT EXISTS dwd_in_out_station_rank (" +
                                          "station Nullable(String),"
                                          + "deal_dates Array(String),"
                                          + "card_nos Array(String),"
                                          + "deal_values Array(String),"
                                          + "deal_types Array(String),"
                                          + "company_names Array(String),"
                                          + "conn_marks Array(String),"
                                          + "deal_moneys Array(String),"
                                          + "equ_nos Array(String),"
                                          + "nums Int64"
                                          + ") ENGINE  = MergeTree() ORDER BY nums"
                                         );
    String dwd_in_out_station_rank_sql =
        "INSERT INTO dwd_in_out_station_rank (station, deal_dates, card_nos, deal_values, deal_types, company_names, conn_marks, deal_moneys, equ_nos, nums) SELECT "
            + "station,"
            + "groupArray(deal_date),"
            + "groupArray(card_no),"
            + "groupArray(deal_value),"
            + "groupArray(deal_type),"
            + "groupArray(company_name),"
            + "groupArray(conn_mark),"
            + "groupArray(deal_money),"
            + "groupArray(equ_no),"
            + "count(*) nums "
            + "FROM dwd_subway_data "
            + "GROUP BY station "
            + "ORDER BY nums DESC";
    statement = connection_.prepareStatement(dwd_in_out_station_rank_sql);
    statement.execute();
```

站点盈利排行榜

```sql
    connection_.createStatement().execute("DROP TABLE IF EXISTS  dwd_station_earning_rank");
    connection_.createStatement().execute("CREATE TABLE IF NOT EXISTS dwd_station_earning_rank (" +
                                          "station String,"
                                          + "company_name String,"
                                          + "deal_value_sum Float64,"
                                          + "deal_money_sum Float64"
                                          + ") ENGINE  = TinyLog()"
                                         );
    String dwd_station_earning_rank_sql =
        "INSERT INTO dwd_station_earning_rank (station, company_name, deal_value_sum, deal_money_sum) SELECT "
        + "station,"
        + "company_name,"
        + "sum(toFloat64OrZero(deal_value))/100 AS deal_value_sum,"
        + "sum(toFloat64OrZero(deal_money))/100 AS deal_money_sum "
        + "FROM dwd_out_station_data "
        + "GROUP BY company_name, station "
        + "ORDER BY deal_value_sum desc";
    statement = connection_.prepareStatement(dwd_station_earning_rank_sql);
    statement.execute();
```

至此，数据仓库的建模就完成了，前端页面通过循环的查询来获取 DWS 层主题的最新情况，展示在动态面板上。



时序图

![image-20210425163340082](/Users/bytedance/Library/Application Support/typora-user-images/image-20210425163340082.png)

类图

<img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20210425234002017.png" alt="image-20210425234002017" style="zoom:50%;" />

<img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20210425234801788.png" alt="image-20210425234801788" style="zoom:50%;" />

<img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20210425235015579.png" alt="image-20210425235015579" style="zoom:50%;" />

<img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20210425235342078.png" alt="image-20210425235342078" style="zoom:50%;" />

<img src="/Users/bytedance/Library/Application Support/typora-user-images/image-20210425235612646.png" alt="image-20210425235612646" style="zoom:50%;" />



### 难点和重点分析

**获取数据**

鉴于地铁刷卡数据有一定的隐私性，所以并没有多少城市将这些数据集公开，在寻找数据的过程中花费了很多时间。浏览了二十多个城市的地铁交通网站，包括北京，上海，成都，广州，深圳等。感谢深圳地铁局提供的宝贵数据，使得本项目可以进行。经过这次经历，我碰到不错的数据集都会收藏起来，以备不时之需。

**模拟实时效果**

深圳地铁网站之前有提供 API 去获取实时的刷卡数据，但是现在没有了。我只拿到了一个离线数据集，所以需要考虑如果模拟成实时的效果，让项目场景更加真实。不同于之前的批处理系统，实时一般要求的是秒级别的延迟，而批处理往往是天级别。在实时技术的选型过程中，需要多个子系统共同协作，相互依赖，最终形成一条数据处理链路。这不同于之前的 hadoop 时代，目前的实时技术并没有一家独大的局面，备选方案很多，开源界百花齐放。分析项目的需求，首先考虑到的就是 flink, 作为实时处理的黑马，其可以作为一条无形的流，将项目整个串起来，同时提供实时效果。然后使用 kafka 作为链路中承前启后的模块，连接了生产者和消费者，确保了数据在链路中的顺利流通。最后一步，就是实时分析，传统的 OLTP 数据库不能满足实时场景，如何选择一个合适的分析型数据库对项目的成功与否至关重要。现阶段可选的 OLAP 数据库有，analyticDB、clickhouse、DorisDB、Presto、Druid等。项目的场景是读请求在请求中占比很高，不会修改已经写入的数据，查询会读取大量的行但是只需要少许的列，一般查询允许的延时大约为100ms，不需要事务。选择 OLAP 数据库的时候主要从这三方面考虑， 性能，数据量，灵活性。以 Presto 为代表的 MPP 架构的 OLAP 数据库可以支持大量的数据并且灵活性也不错，但是一旦查询的复杂度提高或者数据量增大后，其响应就会变慢，不能再提供实时的分析。反观 Clickhouse, 简直就是分析型数据库的黑马，其性能优化做的非常细节，它的性能超过了市面上 90% 的数据库；功能十分丰富，提供了类 SQL的查询，支持嵌套的数据结构和数组；是一款开源的数据库，在开源界十分火爆，成熟度和稳定度要比大多数开源的OLAP数据库好，可以一定程度上降低学习和使用曲线。

**涉及到的组件很多**

在模拟实时效果的难点分析中，提到了很多的存储和中间件系统， 如 redis, clickhouse, flink, kafka。这些系统都是成熟和功能丰富的软件。并且学习成本都是比较高，只有熟悉了这些系统，项目才可以推进。而且在决定使用这些系统前，都做了丰富的调研，横向和纵向对比这些系统的竞争对手，所以前前后后了解和学习了十几种系统，最终才选择了它们，并且对它们进行进一步学习，这个过程是十分耗时和消耗精力的。

**前端实时展示**

不同于普通的各种管理系统的前端，本项目的要求前端类似于一种数据可视化工具，能够实时的动态大屏更新展示；经过调研 DataV, EasyV, echart, FineReport 等都属于这个范畴。DataV  只支持阿里云相关数据哭接入，比如 analyticDB，不支持 clickhouse 的接入。echart 兼容性差，灵活度也不高。最后综合考察决定使用 EasyV, 其特别的支持 Clickhouse 接入，且有视频教程，一定程度可以降低使用曲线，并且灵活，支持自定义，并且提供了样例参考。



### 总结和展望

本文收集了深圳市刷卡离线数据集，利用进站和出站乘客的刷卡数据，借助大数据时代的各种存储和流式系统，把离线的数据集模拟成实时的数据场景，构建 ETL 系统，进行数据仓库建模，通过分析型数据库 Clickhouse 存储数据流并分析站点高峰，分析地铁站时空客流规律和乘客出行特点，最后利用可视化技术把结果呈现出来。挖掘这些信息，对于解决城市交通拥堵问题，优化现有交通网络，进一步规划新的交通线路，保障城市公共交通安全具有重要意义。



### 参考文献























